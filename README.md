




Project
----------------
**Image Captioning**
Generating Captions for images using CNN & LSTM on Flickr8K dataset.This was done with Microsoft Caption Bot AI in mind.link-https://www.captionbot.ai/
Trained model is Model_9.h5.
If you want to learn how exactly this model is generated there is a walkthrough of the whole code in "$your_directory/Image Captioning/Image Captioning Project.ipynb(python notebook)"
Screenshots of funny results are stored in "$your_directory/result_ml_caption"  
How to run in your system
----------------
1. clone this repository by downloading ZIP. Extract.
2. Open Anaconda Prompt.Cd to this directory "$your_directory/Deploying ML Models on Web/Image Captioning/"
3. Do pip install keras==2.2.0
4. Do pip install tensorflow==1.12.0
5. Also install remaining modules and packages whatever you don't have by pip-package-manager.You can find versions of dependencies in "requirements.txt"
6. Do python(3.x) app.py
7. It will successfully run the ML Model on server. Go to http://127.0.0.1:5000// on a browser. After some time server will become active.
8. Select images and have fun!! Some caption are definitely PJs. All image that you will try on this will automatically get stored in "$your_directory/Deploying ML Models on Web/Image Captioning/static"
 

